# My internal benchmark for llm performance for gpt5

## Review:

### **Absolute trash**

It's hard for me to think back to when a model has performed worse, because this is the worst that I can remember a model performed at this task, at least as far as OpenAI models go.

### **Shockingly bad**, are we being trolled?

It took multiple repetitions of error messages and me pointing out that it hadn't changed the code or addressed the mistakes. It's also a very weird implementation, very minimal. This would be appreciated in some contexts, as having minimal dependencies for an audio engine is kind of neat, but it's also strange that none of the audio crates in the rust ecosystem that chatgpt would have previously recommended were used.

Perhaps this is because of a change in approach by OpenAI to minimally use dependencies when possible to avoid dependency management issues that can sometimes cascade with llm code.

### Not just worse than competitors, **worse than GPT-3.5**

In any case, I am overall blown away by how this is not only the worst performing "SoTA" LLM on the market, but how it also seemingly underperforms any of the previous chatgpt models (going back to 3.5 or so) that I have used for this task. I guess there will still be jobs for rust programmers and realtime audio dsp software nerds for awhile more.

Link: https://chatgpt.com/share/6895e5d8-7260-800d-bfae-151912900ff1
